# -*- coding: utf-8 -*-
"""NLP_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1unXdhn0KuJFWcPcbtlhwcOUtT10eDP8g

#Introduction

This project focuses on developing an emotion-based chatbot capable of interpreting and responding to user emotions effectively. The chatbot utilizes machine learning algorithms to analyze textual data and classify it into various emotional categories such as happiness, sadness, anger, and more. By incorporating NLP techniques, this project aims to enhance human-computer interaction by making it more empathetic and intuitive.

Text: Contains written expressions, possibly describing thoughts or feelings related to anxiety and depression.


Label: Numerical values (e.g., 1.0), which might indicate categories or the presence/absence of anxiety or depression
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_excel('/content/drive/MyDrive/datascience/Machine learning/NLP/students anxiety and depression.xlsx')

df.head()

df.info()

df.shape



df.size

df.isnull().any()

df.dropna(inplace=True)

df.duplicated().any()

df.drop_duplicates(inplace=True)

df.duplicated().any()

df.columns



text=df['text']

type(text)

text1=[]

import re

for txt in text:
    # Convert txt to string before applying re.sub
    txt = str(txt)
    txt = re.sub(r'\n', ' ', txt)  # Replace newline characters with space
    txt = re.sub(r'[^a-zA-Z\s]', '', txt)  # Remove punctuation and numbers
    text1.append(txt)  # Append the cleaned text to text1

text1



text=pd.Series(text1)

import nltk
nltk.download('punkt_tab')

# remove sent havind 3 words

from nltk.tokenize import word_tokenize
text = text.apply(lambda x:' '.join([w for w in word_tokenize(x) if len(x)>=3]))

text

# lowecase conversion and normalization (convert in to root form or cut the tail part)

from nltk.stem import SnowballStemmer
stemmer = SnowballStemmer('english')
text = text.apply(lambda x:' '.join([stemmer.stem(w.lower()) for w in word_tokenize(x)]))

text

import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords
stop = stopwords.words('english')
text = text.apply(lambda x:[i for i in word_tokenize(x) if i not in stop]).apply(lambda x:' '.join(x))

text

from sklearn.feature_extraction.text import TfidfVectorizer
vec = TfidfVectorizer()
train_data_vec = vec.fit_transform(text)

print(train_data_vec)

train_data_vec.shape

type(train_data_vec)

y = df['label'].values

y



#bar chart

plt.figure(figsize=(10,5))
sns.barplot(x=df['label'].value_counts().index,y=df['label'].value_counts())
plt.show()

conf_matrix = confusion_matrix(y_test, y_pred)

# percentage distribution of label

df['label'].value_counts(normalize=True)*100

#Box plot
plt.figure(figsize=(10,5))
sns.boxplot(x=df['label'],y=df['text'].str.len())
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Scatter plot
plt.figure(figsize=(8, 5))
sns.scatterplot(x=df['label'], y=df['text'].str.len())
plt.xlabel('Label')
plt.ylabel('Text Length')
plt.title('Scatter Plot of Text Length vs Label')
plt.show()

# Histogram
plt.figure(figsize=(10, 5))
sns.histplot(df['text'].str.len(), bins=30)
plt.xlabel('Text Length')
plt.ylabel('Frequency')
plt.title('Histogram of Text Length')
plt.show()

plt.figure(figsize=(7, 5))
sns.lineplot(x=df['text'], y=df['label'], ci=None)
plt.title("Line plot of text length vs label")
plt.xlabel("Text length")
plt.ylabel("Label")
plt.show()

# Swarmplot
plt.figure(figsize=(10, 5))
sns.swarmplot(x=df['label'], y=df['text'].str.len(), size=7)
plt.xlabel('Label')
plt.ylabel('Text Length')
plt.title('Swarm Plot of Text Length vs Label')
plt.show()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(train_data_vec,y,test_size=0.2,random_state=42)

print("x_train : ", (x_train.shape))
print("x_test : ", {x_test.shape})
print("y_train : ", {y_train.shape})
print("y_test : ", {y_test.shape})

vectorizer = TfidfVectorizer()

x_train_vec = x_train
x_test_vec = x_test

#scaling x_train and x_test
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train_vec.toarray()) # Convert to dense array if necessary
x_test_scaled = scaler.transform(x_test_vec.toarray())

# saving the scaler model
import pickle
pickle.dump(scaler,open('Scalermod.pkl','wb'))

"""MODEL EVALUATION

Logistic regression()
"""

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

model.fit(x_train,y_train)

y_pred = model.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)

x_test_pred = model.predict(x_test)
test_accuracy = accuracy_score(y_test,x_test_pred)
test_accuracy



text='trouble sleeping confused mind restless heart All out of tune'

import numpy as np

model.predict(vec.transform(np.array([text])))

"""MultinomialNB()"""

from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()

model.fit(x_train,y_train)

y_pred = model.predict(x_test)
y_pred

from sklearn.metrics import accuracy_score,confusion_matrix
accuracy_score(y_test,y_pred)



conf_matrix = confusion_matrix(y_test, y_pred)

#Heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="pink", xticklabels=['0,1'], yticklabels=['0,1'])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

from sklearn.naive_bayes import MultinomialNB

nb_model = MultinomialNB()
nb_model.fit(x_train, y_train)

# Predictions and evaluation
y_pred_nb = nb_model.predict(x_test)
print("Naive Bayes Accuracy:", accuracy_score(y_test, y_pred_nb))

# New prediction
sample = "CIts really easy to enter the afternoon of the trip"

print("The result of sample message :  " ,model.predict(vec.transform([sample])))

"""#Conclusion

In this project, we successfully implemented an emotion-based chatbot leveraging NLP and machine learning techniques. The chatbot demonstrated its ability to accurately interpret user emotions from textual inputs and provide appropriate responses, showcasing the potential of NLP in enhancing interactive systems. Through this project, we gained valuable insights into the challenges of emotion classification and the importance of refining algorithms for improved accuracy andÂ reliability.
"""